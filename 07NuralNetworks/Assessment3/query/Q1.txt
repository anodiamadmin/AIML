The previous version of the report's "Validation Set Usage" section says the following:
-----------------
Although the project specification allows for train_val_split = 1 (training on all available images), during experimentation, a temporary hold-out validation split (e.g., 95:5) was created to tune learning rate, dropout rate, stochastic depth probability, and augmentation parameters. This separation ensured that all optimization decisions were informed by unseen data rather than the training set, thereby minimizing the risk of overfitting.
Metrics computed on the validation set included:
•	Top-1 classification accuracy
•	Cross-entropy loss trend
•	Confusion matrix to identify breed-specific misclassifications
By monitoring these metrics across epochs, optimal stopping points and scheduler configurations were identified before final training on the full dataset.
--------------------
I have 8 classes of cats with 1000 images of each. I took out 50 images from each class for validation (400 validation images). I trained with remaining 950 images from each class (15600 training images).

When I used train_val_split = 0.8 and trained for 40 epochs.
The output from a3main.py showed consistant increase of both training and test accuracies and both went greater than 80-85% by the 40th epoch.

The output from validation.py on the unseen vaidation-set (400 heldout images, 50images from each of the 8 classes) is as follows:
PS D:\anodiam\AIML\07NuralNetworks\Assessment3\a3Validation> python validation.py
Validated on 400 images
Overall accuracy: 83.75%

Confusion matrix (rows = true, cols = predicted):
[[45  1  0  1  0  0  2  1]
 [ 0 38  0  2  4  0  4  2]
 [ 0  1 34  5  3  3  1  3]
 [ 2  0  2 43  0  1  1  1]
 [ 0  1  2  2 43  0  0  2]
 [ 0  1  0  0  0 48  1  0]
 [ 0  2  1  1  0  4 41  1]
 [ 3  2  0  0  0  0  2 43]]

Per-class accuracy:
  Class 0: 90.00%  (45/50)
  Class 1: 76.00%  (38/50)
  Class 2: 68.00%  (34/50)
  Class 3: 86.00%  (43/50)
  Class 4: 86.00%  (43/50)
  Class 5: 96.00%  (48/50)
  Class 6: 82.00%  (41/50)
  Class 7: 86.00%  (43/50)
-----------------------------------------
Next I used the same 400 validation images and 15600 training images, but train_val_split = 1 and trained for 50 epochs.
The output from a3main.py is as follows:


The output from validation.py on the unseen vaidation-set (400 heldout images, 50images from each of the 8 classes) is as follows:


----------------------------------------

Rewrite the report's "Validation Set Usage" section as per the above findings.
